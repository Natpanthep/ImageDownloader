from pathlib import Path
from PIL import Image
import imagehash
import os

def remove_duplicate_images(dataset_root):
    print(f"ğŸ” Scanning for duplicates in: {dataset_root}")
    image_hashes = set()
    duplicates = []

    dataset_path = Path(dataset_root)

    for image_path in dataset_path.rglob("*.*"):
        try:
            with Image.open(image_path) as img:
                img_hash = imagehash.average_hash(img)
            if img_hash in image_hashes:
                duplicates.append(image_path)
            else:
                image_hashes.add(img_hash)
        except Exception as e:
            print(f"âš ï¸ Failed to process {image_path}: {e}")

    print(f"\nğŸ§¹ Found {len(duplicates)} duplicate images. Deleting...")
    for dup in duplicates:
        try:
            os.remove(dup)
            print(f"ğŸ—‘ï¸ Deleted: {dup}")
        except Exception as e:
            print(f"âŒ Failed to delete {dup}: {e}")

    print("\nâœ… Done cleaning duplicates.")

# âœ… à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¸‡à¸²à¸™
remove_duplicate_images(r"D:\drone_dataset")
